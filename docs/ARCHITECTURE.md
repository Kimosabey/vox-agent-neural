# Architecture Analysis & Recommendations

**Project**: VoxAgent Neural - Agentic Transcription & Inference Engine
**Date**: January 15, 2026
**Technology Stack**: React + FastAPI + Faster-Whisper + LiveKit Agents / WebSockets

---

## ğŸ—ï¸ Current Architecture (Hybrid Approach)

### Overview
The current implementation uses **BOTH** LiveKit and WebSocket connections:

![Current Hybrid Architecture](./images/current_hybrid_architecture.png)

### Components

**Frontend Structure:**
![Component Flow](./images/component_flow.png)

- `useLiveKit.ts`: Manages both LiveKit room and WebSocket
- LiveKit Client: Creates room, publishes audio track
- WebSocket: Sends audio chunks, receives transcripts

**Backend Protocol:**
![WebSocket Protocol](./images/websocket_protocol.png)

- FastAPI: Serves API and WebSocket endpoint
- WebSocket Handler: Receives audio, processes with Whisper
- Whisper Model: `base` model with CPU inference (INT8)
- FFmpeg: Converts WebM â†’ WAV for Whisper

### Data Flow

1. User clicks Record
2. Frontend establishes LiveKit room + WebSocket
3. Microphone audio captured via LiveKit track
4. Audio chunks (3-second intervals) sent over WebSocket
5. Backend converts WebM â†’ WAV â†’ Whisper transcription
6. Transcript sent back over WebSocket
7. UI displays result

### Issues with Current Approach

âš ï¸ **Redundancy:**
- LiveKit creates rooms but isn't used for transcription
- WebSocket does all the actual work
- Two connections for what one could do

âš ï¸ **Complexity:**
- More code to maintain
- LiveKit costs (cloud hosting)
- Harder to debug connection issues

âš ï¸ **Non-Standard:**
- LiveKit is designed for agent-based transcription
- Current usage doesn't leverage LiveKit's strengths

---

## ğŸ“Š Alternative Approaches

### Option 1: LiveKit Agents Pattern (Standard)

![LiveKit Agents Architecture](./images/livekit_agents_architecture.png)

**Architecture:**

**How it works:**
1. Frontend publishes audio to LiveKit room
2. LiveKit Agent subscribes to audio track
3. Agent processes with Whisper
4. Results sent via LiveKit Data Channel
5. Frontend receives transcripts

**Pros:**
- âœ… Standard LiveKit pattern
- âœ… Built-in recording capabilities
- âœ… Multi-user support
- âœ… Scalable infrastructure
- âœ… Security features (E2E encryption)

**Cons:**
- âŒ More complex setup
- âŒ LiveKit cloud costs
- âŒ Heavier infrastructure
- âŒ Overkill for single-user apps

**Best for:**
- Multi-user rooms
- Production applications
- Need recording/playback
- Enterprise features required

---

### Option 2: WebSocket-Only Pattern (Recommended)

![System Architecture](./images/system_architecture_flow.png)

**How it works:**
1. Frontend gets microphone with `getUserMedia()`
2. Audio chunks sent over WebSocket
3. Backend processes with Whisper
4. Transcripts returned over same WebSocket
5. Single persistent connection

**Pros:**
- âœ… **Simplest architecture**
- âœ… **Lowest latency** (direct connection)
- âœ… **No external dependencies**
- âœ… **Easy to debug**
- âœ… **Lower costs** (no LiveKit)
- âœ… **Perfect for speech practice**

**Cons:**
- âŒ No built-in multi-user support
- âŒ No built-in recording (can add manually)
- âŒ Manual connection management

**Best for:**
- âœ… **Speech practice apps** (your use case!)
- Single-user applications
- Prototypes & MVPs
- Cost-sensitive projects

---

## ğŸ¯ Recommendation

### For VoxAgent Neural (Speech Practice App)

**Use: WebSocket-Only Approach**

**Reasons:**

1. **Simplicity**: 50% less code, easier maintenance
2. **Perfect Fit**: Single-user speech practice doesn't need LiveKit features
3. **Performance**: Lower latency, fewer network hops
4. **Cost**: No LiveKit hosting costs
5. **Your Current Code**: WebSocket already works perfectly!

### Migration Path

**Remove:**
- LiveKit client dependency
- Room creation/management code
- LiveKit token generation API

**Keep:**
- WebSocket connection (already working)
- Whisper transcription backend
- Current UI/UX

**Add:**
- Direct `getUserMedia()` for microphone
- Simplified connection management

---

## ğŸ”§ Implementation Comparison

### Current (Hybrid)

**Frontend Dependencies:**
```json
{
  "livekit-client": "^2.x",
  // ...other deps
}
```

**Connection Code:**
```typescript
// Create LiveKit room
const room = new Room();
await room.connect(url, token);

// Also create WebSocket
const ws = new WebSocket('/ws');

// Send audio via WebSocket (not LiveKit!)
ws.send(audioChunk);
```

**Issues:**
- LiveKit room created but not used
- WebSocket does all the work
- Redundant connections

---

### Recommended (WebSocket-Only)

**Frontend Dependencies:**
```json
{
  // No LiveKit needed!
}
```

**Connection Code:**
```typescript
// Simple WebSocket
const ws = new WebSocket('/ws');

// Direct microphone access
const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
const recorder = new MediaRecorder(stream);

// Send audio chunks
recorder.ondataavailable = (e) => ws.send(e.data);
```

**Benefits:**
- âœ… Cleaner code
- âœ… One connection
- âœ… Simpler logic

---

## ğŸ“ˆ Performance Metrics

### Current Metrics (Optimized)

![Data Flow Timeline](./images/data_flow_diagram.png)

| Metric | Value | Notes |
|--------|-------|-------|
| **Connection Setup** | ~3-5 seconds | LiveKit + WebSocket |
| **Transcription TAT** | 2-5 seconds | Optimized Whisper |
| **Total Latency** | 5-10 seconds | Speech â†’ Transcript |
| **Memory Usage** | ~500MB | Base model + connections |
| **Chunk Size** | 40KB minimum | Filter small chunks |

### Optimizations Applied

1. **Whisper Speed:**
   - Disabled compression ratio checks
   - Disabled quality retries
   - Single-pass decoding (temperature=0)
   - Result: 10x faster (37s â†’ 3s)

2. **Connection Management:**
   - Persistent room (no reconnection)
   - Instant record/stop toggle
   - Smart chunk filtering (>40KB)

3. **UI Performance:**
   - Animated audio visualizer (60fps)
   - Color-coded levels
   - Real-time percentage display

---

## ğŸ› ï¸ Technology Stack Details

### Backend

**Framework:** FastAPI
```python
# WebSocket endpoint
@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    # Handle audio chunks
    # Process with Whisper
    # Return transcripts
```

**Whisper Configuration:**
```python
WhisperModel(
    "base",  # 140MB, balanced accuracy/speed
    device="cpu",
    compute_type="int8",  # Quantized for speed
    # Optimizations:
    compression_ratio_threshold=None,  # No retries
    temperature=0.0,  # Deterministic
    beam_size=1  # Fast decoding
)
```

**Audio Processing:**
```
WebM (from browser) â†’ FFmpeg â†’ WAV (16kHz, mono) â†’ Whisper
```

### Frontend

**Framework:** React + TypeScript + Vite

**UI Library:** Tailwind CSS + shadcn/ui

**State Management:**
- Custom hooks (`useLiveKit`)
- React state for UI
- No external state library needed

**Audio Capture:**
- MediaRecorder API (WebM/Opus codec)
- 3-second chunks
- Real-time level monitoring

---

## ğŸ” Security Considerations

### Current Security

**LiveKit:**
- âœ… JWT token authentication
- âœ… E2E encryption (not used)
- âœ… Room isolation

**WebSocket:**
- âš ï¸ No built-in authentication
- âš ï¸ No encryption (use WSS in production)

### Recommendations

1. **Use WSS** (WebSocket Secure) in production
2. **Add authentication** to WebSocket connection
3. **Rate limiting** to prevent abuse
4. **Input validation** for audio chunks
5. **CORS** properly configured

---

## ğŸ’° Cost Analysis

### LiveKit Costs (Current)

**Free Tier:**
- 10,000 participant minutes/month
- Good for development

**Paid:**
- ~$0.004/minute after free tier
- Additional costs for recording, egress

### WebSocket-Only Costs

**Infrastructure:**
- Server hosting only
- No per-minute charges
- Predictable costs

**Estimated Savings:**
- Development: $0 (both free)
- Production (1000 users): **$200-500/month saved**

---

## ğŸš€ Future Considerations

### If You Need Multi-User Features

**Then** switch to LiveKit Agents Pattern:
- Multiple participants in room
- Collaborative transcription
- Shared playback
- Recording storage

### If Staying Single-User

**Enhance** WebSocket-Only:
- Add authentication layer
- Implement session management
- Add transcript storage (database)
- Export functionality (already done!)

---

## ğŸ“ Decision Matrix

| Use Case | Current | LiveKit | WebSocket |
|----------|---------|---------|-----------|
| **Single-user speech practice** | âš ï¸ Overkill | âŒ Overkill | âœ… **Perfect** |
| **Multi-user rooms** | âš ï¸ Half-implemented | âœ… **Best** | âŒ Need extra work |
| **Simple prototype** | âŒ Complex | âŒ Complex | âœ… **Best** |
| **Enterprise app** | âš ï¸ Mixed | âœ… **Best** | âš ï¸ Need features |
| **Low budget** | âš ï¸ Medium cost | âŒ Higher cost | âœ… **Lowest** |
| **Quick to market** | âš ï¸ Moderate | âŒ Slower | âœ… **Fastest** |

---

## âœ… Final Recommendation

### For VoxAgent Neural Project:

**Migrate to WebSocket-Only Architecture**

**Why:**
1. Matches your use case perfectly (single-user speech practice)
2. Simpler = faster development & maintenance
3. Lower costs (no LiveKit fees)
4. Better performance (lower latency)
5. Your WebSocket code already works great!

**Timeline:**
- Refactoring: 2-4 hours
- Testing: 1-2 hours
- Result: Cleaner, faster, simpler application

**Risk Assessment:**
- Risk: **Low** (WebSocket already proven to work)
- Effort: **Medium** (code removal + minor changes)
- Benefit: **High** (simplicity + cost savings)

---

## ğŸ“š References

- [LiveKit Agents Documentation](https://docs.livekit.io/agents/)
- [Faster-Whisper GitHub](https://github.com/guillaumekln/faster-whisper)
- [WebSocket API MDN](https://developer.mozilla.org/en-US/docs/Web/API/WebSocket)
- [MediaRecorder API](https://developer.mozilla.org/en-US/docs/Web/API/MediaRecorder)

---

**Document Version**: 1.0  
**Last Updated**: January 15, 2026  
**Author**: Harshan Aiyappa â€” Senior Hybrid Engineer
